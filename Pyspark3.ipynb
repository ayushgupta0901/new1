{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pyspark HAndling Mssing Values\n",
    "\n",
    "    *Dropping Columns\n",
    "    *Dropping Rows\n",
    "    *Various parameter in F=Dropping Functionalities\n",
    "    *Handling Mssing Values by Mean , Median and Mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName('Practise3').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark=spark.read.csv('f:/Spark/Data3.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+------+\n",
      "|    Name| Age|Experience|Salary|\n",
      "+--------+----+----------+------+\n",
      "|   Ayush|  20|         4| 10000|\n",
      "|    Yash|  21|         3| 19000|\n",
      "|  Prerna|  19|         1| 15000|\n",
      "|   Nitan|  21|         2| 25000|\n",
      "|Vikramye|null|      null| 12000|\n",
      "|    null|  29|         2| 40000|\n",
      "|    null|  10|      null|  null|\n",
      "+--------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+------+\n",
      "| Age|Experience|Salary|\n",
      "+----+----------+------+\n",
      "|  20|         4| 10000|\n",
      "|  21|         3| 19000|\n",
      "|  19|         1| 15000|\n",
      "|  21|         2| 25000|\n",
      "|null|      null| 12000|\n",
      "|  29|         2| 40000|\n",
      "|  10|      null|  null|\n",
      "+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## How tpo Drop columns\n",
    "df_pyspark.drop('Name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+------+\n",
      "|    Name| Age|Experience|Salary|\n",
      "+--------+----+----------+------+\n",
      "|   Ayush|  20|         4| 10000|\n",
      "|    Yash|  21|         3| 19000|\n",
      "|  Prerna|  19|         1| 15000|\n",
      "|   Nitan|  21|         2| 25000|\n",
      "|Vikramye|null|      null| 12000|\n",
      "|    null|  29|         2| 40000|\n",
      "|    null|  10|      null|  null|\n",
      "+--------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------+\n",
      "|  Name|Age|Experience|Salary|\n",
      "+------+---+----------+------+\n",
      "| Ayush| 20|         4| 10000|\n",
      "|  Yash| 21|         3| 19000|\n",
      "|Prerna| 19|         1| 15000|\n",
      "| Nitan| 21|         2| 25000|\n",
      "+------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+------+\n",
      "|    Name| Age|Experience|Salary|\n",
      "+--------+----+----------+------+\n",
      "|   Ayush|  20|         4| 10000|\n",
      "|    Yash|  21|         3| 19000|\n",
      "|  Prerna|  19|         1| 15000|\n",
      "|   Nitan|  21|         2| 25000|\n",
      "|Vikramye|null|      null| 12000|\n",
      "|    null|  29|         2| 40000|\n",
      "|    null|  10|      null|  null|\n",
      "+--------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## any==how\n",
    "df_pyspark.na.dropQ(how='all').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------+\n",
      "|  Name|Age|Experience|Salary|\n",
      "+------+---+----------+------+\n",
      "| Ayush| 20|         4| 10000|\n",
      "|  Yash| 21|         3| 19000|\n",
      "|Prerna| 19|         1| 15000|\n",
      "| Nitan| 21|         2| 25000|\n",
      "+------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(how='any').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------+\n",
      "|  Name|Age|Experience|Salary|\n",
      "+------+---+----------+------+\n",
      "| Ayush| 20|         4| 10000|\n",
      "|  Yash| 21|         3| 19000|\n",
      "|Prerna| 19|         1| 15000|\n",
      "| Nitan| 21|         2| 25000|\n",
      "|  null| 29|         2| 40000|\n",
      "+------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###threshold ##Atleast non-values\n",
    "df_pyspark.na.drop(how='any',thresh=3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------+\n",
      "|  Name|Age|Experience|Salary|\n",
      "+------+---+----------+------+\n",
      "| Ayush| 20|         4| 10000|\n",
      "|  Yash| 21|         3| 19000|\n",
      "|Prerna| 19|         1| 15000|\n",
      "| Nitan| 21|         2| 25000|\n",
      "|  null| 29|         2| 40000|\n",
      "+------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##subset\n",
    "df_pyspark.na.drop(how='any',subset=['Experience']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+------+\n",
      "|    Name| Age|Experience|Salary|\n",
      "+--------+----+----------+------+\n",
      "|   Ayush|  20|         4| 10000|\n",
      "|    Yash|  21|         3| 19000|\n",
      "|  Prerna|  19|         1| 15000|\n",
      "|   Nitan|  21|         2| 25000|\n",
      "|Vikramye|null|      1900| 12000|\n",
      "|    null|  29|         2| 40000|\n",
      "|    null|  10|      1900|  null|\n",
      "+--------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Filling the missing values\n",
    "df_pyspark.na.fill(1900, subset=['Experience']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+------+\n",
      "|    Name| Age|Experience|Salary|\n",
      "+--------+----+----------+------+\n",
      "|   Ayush|  20|         4| 10000|\n",
      "|    Yash|  21|         3| 19000|\n",
      "|  Prerna|  19|         1| 15000|\n",
      "|   Nitan|  21|         2| 25000|\n",
      "|Vikramye|null|      null| 12000|\n",
      "|    null|  29|         2| 40000|\n",
      "|    null|  10|      null|  null|\n",
      "+--------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer= Imputer(\n",
    "        inputCols=['Age','Experience','Salary'],\n",
    "        outputCols=[\"{}_imputs\".format(c) for c in ['Age','Experience','Salary']]\n",
    "        ).setStrategy('mean')\n",
    "## Mean, Median ,Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+------+----------+-----------------+-------------+\n",
      "|    Name| Age|Experience|Salary|Age_imputs|Experience_imputs|Salary_imputs|\n",
      "+--------+----+----------+------+----------+-----------------+-------------+\n",
      "|   Ayush|  20|         4| 10000|        20|                4|        10000|\n",
      "|    Yash|  21|         3| 19000|        21|                3|        19000|\n",
      "|  Prerna|  19|         1| 15000|        19|                1|        15000|\n",
      "|   Nitan|  21|         2| 25000|        21|                2|        25000|\n",
      "|Vikramye|null|      null| 12000|        20|                2|        12000|\n",
      "|    null|  29|         2| 40000|        29|                2|        40000|\n",
      "|    null|  10|      null|  null|        10|                2|        20166|\n",
      "+--------+----+----------+------+----------+-----------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputer.fit(df_pyspark).transform(df_pyspark).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
